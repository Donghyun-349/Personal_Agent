name: Run Scraper Manually

on:
  workflow_dispatch:
    inputs:
      url:
        description: 'URL to scrape'
        required: true

jobs:
  scrape_and_summarize:
    runs-on: ubuntu-latest

    permissions:
      contents: read

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y fonts-nanum

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      - name: Install Playwright Browsers & Deps
        run: |
          python -m playwright install chromium
          sudo python -m playwright install-deps chromium

      - name: Run Scraper
        env:
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
          GOOGLE_TOKEN_JSON: ${{ secrets.GOOGLE_TOKEN_JSON }}
          GOOGLE_DRIVE_FOLDER_ID: ${{ secrets.GOOGLE_DRIVE_FOLDER_ID }}
          TARGET_URL: ${{ inputs.url }}
        run: |
          python test_local.py

      - name: Upload Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scraper-output
          path: test_output/
